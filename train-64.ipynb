{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os \n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random \n",
    "import cv2\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataloader:\n",
    "    def __init__(self):\n",
    "        self.mainDIR = os.listdir('.')\n",
    "        self.files = os.listdir('./Dataset/')\n",
    "        self.masterDataset = pd.read_csv('dataSet.csv')\n",
    "        print(\"MAINDATASET : \", self.masterDataset.shape)\n",
    "        for file in self.mainDIR:\n",
    "            try:\n",
    "                int(file)\n",
    "                self.files.append(file)\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        self.mainCSV = pd.DataFrame(columns = ['X', 'Y', #Of the actual data\n",
    "                                                'frameName', # ADD THE FILE NAME HERE TO STOP DUPLICATION\n",
    "                                                'Xcam', 'Ycam', 'Orientation',\n",
    "                                                'faceXmin', 'faceYmin',\n",
    "                                                'faceXmax', 'faceYmax', 'faceValid',\n",
    "                                                \n",
    "                                                'leftEyeXmin', 'leftEyeYmin',\n",
    "                                                'leftEyeXmax', 'leftEyeYmax', 'leftEyeValid',\n",
    "                                                \n",
    "                                                'rightEyeXmin', 'rightEyeYmin',\n",
    "                                                'rightEyeXmax', 'rightEyeYmax', 'rightEyeValid',\n",
    "                                                \n",
    "                                                # 25 X 25 grid\n",
    "                                                'faceGirdXmin', 'faceGridYmin',\n",
    "                                                'faceGridXmax', 'faceGridYmax', 'faceGridValid',\n",
    "                                                \n",
    "                                                'screenHeight', 'screenWidth', 'Device'\n",
    "                                                ])\n",
    "        \n",
    "        self.masterDataset = pd.read_csv('dataSet.csv')\n",
    "        self.splitcolumn = int(self.masterDataset.shape[0] * 0.9)\n",
    "        self.trainCSV = self.masterDataset.head(self.splitcolumn)\n",
    "        self.testCSV = self.masterDataset.tail(self.masterDataset.shape[0] - self.splitcolumn)\n",
    "    \n",
    "    def mainCSVcreator(self):\n",
    "        print(\"IN MAIN CSV CREATOR\")\n",
    "        self.files = os.listdir('./Dataset/')\n",
    "        first = True\n",
    "        n = 0\n",
    "        for file in self.files:\n",
    "            print(file)\n",
    "            n += 1\n",
    "            try:\n",
    "                face = pd.read_json('./Dataset/' + file + '/appleFace.json')\n",
    "                leftEye = pd.read_json('./Dataset/' + file + '/appleLeftEye.json')\n",
    "                rightEye = pd.read_json('./Dataset/' + file + '/appleRightEye.json')\n",
    "                dotInfo = pd.read_json('./Dataset/' + file + '/dotInfo.json')\n",
    "                faceGrid = pd.read_json('./Dataset/' + file + '/faceGrid.json')\n",
    "                frames = pd.read_json('./Dataset/' + file + '/frames.json')\n",
    "                info = pd.read_json('./Dataset/' + file + '/info.json', typ='series')\n",
    "                motion = pd.read_json('./Dataset/' + file + '/motion.json')\n",
    "                screen = pd.read_json('./Dataset/' + file + '/screen.json')\n",
    "                \n",
    "                numImages = os.listdir('./Dataset/' + file + '/frames/')\n",
    "                if frames[0].shape[0] != len(numImages):\n",
    "                    print(\"NOT SAME NUMBER\")\n",
    "                    break\n",
    "            except Exception as ex:\n",
    "                print(\"ECEPTION  :  \" + str(ex))\n",
    "                break\n",
    "            \n",
    "            tempDF = pd.DataFrame()\n",
    "            \n",
    "            tempDF['X'] = dotInfo['XPts']\n",
    "            tempDF['Y'] = dotInfo['YPts']\n",
    "            tempDF['frameName'] = file + '/frames/' + frames[0]\n",
    "            tempDF['Xcam'] = dotInfo['XCam']\n",
    "            tempDF['Ycam'] = dotInfo['YCam']\n",
    "            tempDF['Orientation'] = screen['Orientation']\n",
    "            \n",
    "            tempDF['faceXmin'] = face['X']\n",
    "            tempDF['faceYmin'] = face['Y']\n",
    "            tempDF['faceXmax'] = face['X'] + face['W']\n",
    "            tempDF['faceYmax'] = face['Y'] + face['H']\n",
    "            tempDF['faceValid'] = face['IsValid']\n",
    "            \n",
    "            tempDF['leftEyeXmin'] = leftEye['X']\n",
    "            tempDF['leftEyeYmin'] = leftEye['Y']\n",
    "            tempDF['leftEyeXmax'] = leftEye['X'] + leftEye['W']\n",
    "            tempDF['leftEyeYmax'] = leftEye['Y'] + leftEye['H']\n",
    "            tempDF['leftEyeValid'] = leftEye['IsValid']\n",
    "            \n",
    "            tempDF['rightEyeXmin'] = rightEye['X']\n",
    "            tempDF['rightEyeYmin'] = rightEye['Y']\n",
    "            tempDF['rightEyeXmax'] = rightEye['X'] + rightEye['W']\n",
    "            tempDF['rightEyeYmax'] = rightEye['Y'] + rightEye['H']\n",
    "            tempDF['rightEyeValid'] = rightEye['IsValid']\n",
    "            \n",
    "            tempDF['faceGridXmin'] = faceGrid['X']\n",
    "            tempDF['faceGridYmin'] = faceGrid['Y']\n",
    "            tempDF['faceGridXmax'] = faceGrid['X'] + faceGrid['W']\n",
    "            tempDF['faceGridYmax'] = faceGrid['Y'] + faceGrid['H']\n",
    "            tempDF['faceGridValid'] = faceGrid['IsValid']\n",
    "            \n",
    "            tempDF['screenHeight'] = screen['H']\n",
    "            tempDF['screenWidth'] = screen['W']\n",
    "            tempDF['Device'] = info['DeviceName']\n",
    "            \n",
    "            print(tempDF.shape)\n",
    "            \n",
    "            for i in range(tempDF.shape[0]):\n",
    "                #print(tempDF.iloc[i]['faceValid'], tempDF[i]['leftEyeValid'], tempDF[i]['rightEyeValid'], tempDF[i]['faceGridValid'])\n",
    "                if (tempDF.loc[i]['faceValid'] == 0 or tempDF.loc[i]['leftEyeValid'] == 0 or\n",
    "                    tempDF.loc[i]['rightEyeValid'] == 0 or tempDF.loc[i]['faceGridValid'] == 0 or \n",
    "                    tempDF.loc[i]['leftEyeXmax'] < 0 or tempDF.loc[i]['leftEyeYmax'] < 0 or \n",
    "                    tempDF.loc[i]['leftEyeXmin'] < 0 or tempDF.loc[i]['leftEyeYmin'] < 0 or \n",
    "                    tempDF.loc[i]['rightEyeXmax'] < 0 or tempDF.loc[i]['rightEyeYmax'] < 0 or \n",
    "                    tempDF.loc[i]['rightEyeXmin'] < 0 or tempDF.loc[i]['rightEyeYmin'] < 0 or \n",
    "                    tempDF.loc[i]['faceXmax'] < 0 or tempDF.loc[i]['faceYmax'] < 0 or \n",
    "                    tempDF.loc[i]['faceXmin'] < 0 or tempDF.loc[i]['faceYmin'] < 0):\n",
    "                    tempDF = tempDF.drop(i, axis = 0)\n",
    "                \n",
    "            \n",
    "            if first is True:\n",
    "                self.mainCSV = tempDF\n",
    "                tempDF = None\n",
    "                first = False \n",
    "            else:\n",
    "                print(self.mainCSV.shape)\n",
    "                self.mainCSV = self.mainCSV.append(tempDF)\n",
    "                tempDF = None\n",
    "                \n",
    "            if n % 50 == 0:\n",
    "                self.mainCSV.to_csv('dataSet.csv')\n",
    "        \n",
    "        self.mainCSV.to_csv('dataSet.csv')\n",
    "    \n",
    "    def getEpochs_train(self, size):\n",
    "        return self.trainCSV.shape[0] // size - 8000\n",
    "    \n",
    "    def getEpochs_test(self, size):\n",
    "        return self.testCSV.shape[0] // size - 800\n",
    "\n",
    "    def load_data_train(self, batchSize):\n",
    "        masterDataset = self.trainCSV\n",
    "        \n",
    "        while True:\n",
    "            leftEyeImage, rightEyeImage, faceImage, Grids = None, None, None, None\n",
    "            rows = random.sample(range(0, masterDataset.shape[0]), batchSize)\n",
    "            miniDataset = masterDataset.iloc[rows]\n",
    "            \n",
    "            trainY = miniDataset[['Xcam', 'Ycam']].to_numpy()\n",
    "            \n",
    "            faceImage = None\n",
    "            First = True\n",
    "            for i in range(batchSize):\n",
    "                if First is True:\n",
    "                    #print(miniDataset.iloc[i]['frameName'])\n",
    "                    img = cv2.imread('./Dataset/' + miniDataset.iloc[i]['frameName'])\n",
    "                    faceGrid = np.array([np.zeros((25,25))])\n",
    "                    faceGrid[0][miniDataset.iloc[i]['faceGridYmin']:miniDataset.iloc[i]['faceGridYmax'], miniDataset.iloc[i]['faceGridXmin']:miniDataset.iloc[i]['faceGridXmax']] = 1\n",
    "                    \n",
    "                    Grids = faceGrid\n",
    "                    faceImage = np.array([cv2.resize(img[int(miniDataset.iloc[i]['faceYmin']):int(miniDataset.iloc[i]['faceYmax']), int(miniDataset.iloc[i]['faceXmin']):int(miniDataset.iloc[i]['faceXmax']), :], (64,64), interpolation=cv2.INTER_AREA)  ])\n",
    "                    leftEyeImage = np.array([cv2.resize(img[int(miniDataset.iloc[i]['leftEyeYmin']):int(miniDataset.iloc[i]['leftEyeYmax']), int(miniDataset.iloc[i]['leftEyeXmin']):int(miniDataset.iloc[i]['leftEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)])\n",
    "                    rightEyeImage = np.array([cv2.resize(img[int(miniDataset.iloc[i]['rightEyeYmin']):int(miniDataset.iloc[i]['rightEyeYmax']), int(miniDataset.iloc[i]['rightEyeXmin']):int(miniDataset.iloc[i]['rightEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)])\n",
    "                    First = False   \n",
    "                else:\n",
    "                    img = cv2.imread('./Dataset/' + miniDataset.iloc[i]['frameName'])\n",
    "                    faceGrid = np.array([np.zeros((25,25))])\n",
    "                    faceGrid[0][miniDataset.iloc[i]['faceGridYmin']:miniDataset.iloc[i]['faceGridYmax'], miniDataset.iloc[i]['faceGridXmin']:miniDataset.iloc[i]['faceGridXmax']] = 1\n",
    "                    \n",
    "                    #print(leftEyeImage.shape, rightEyeImage.shape, faceImage.shape, Grids.shape)\n",
    "                    \n",
    "                    Grids = np.append(Grids, faceGrid, axis = 0)\n",
    "                    leftEyeImage = np.append(leftEyeImage, np.array([cv2.resize(img[int(miniDataset.iloc[i]['leftEyeYmin']):int(miniDataset.iloc[i]['leftEyeYmax']), int(miniDataset.iloc[i]['leftEyeXmin']):int(miniDataset.iloc[i]['leftEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)]), axis = 0)\n",
    "                    rightEyeImage = np.append(rightEyeImage, np.array([cv2.resize(img[int(miniDataset.iloc[i]['rightEyeYmin']):int(miniDataset.iloc[i]['rightEyeYmax']), int(miniDataset.iloc[i]['rightEyeXmin']):int(miniDataset.iloc[i]['rightEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)]), axis = 0)\n",
    "                    faceImage = np.append(faceImage, np.array([cv2.resize( img[int(miniDataset.iloc[i]['faceYmin']):int(miniDataset.iloc[i]['faceYmax']), int(miniDataset.iloc[i]['faceXmin']):int(miniDataset.iloc[i]['faceXmax']), :] , (64,64), interpolation=cv2.INTER_AREA)  ]), axis = 0)\n",
    "                    \n",
    "            #print(\"END : \" , leftEyeImage.shape, rightEyeImage.shape, faceImage.shape, Grids.shape)\n",
    "            yield [leftEyeImage, rightEyeImage, faceImage, Grids], trainY\n",
    "\n",
    "    def load_data_test(self, batchSize):\n",
    "        masterDataset = self.testCSV\n",
    "        \n",
    "        while True:\n",
    "            leftEyeImage, rightEyeImage, faceImage, Grids = None, None, None, None\n",
    "            rows = random.sample(range(0, masterDataset.shape[0]), batchSize)\n",
    "            miniDataset = masterDataset.iloc[rows]\n",
    "            \n",
    "            trainY = miniDataset[['Xcam', 'Ycam']].to_numpy()\n",
    "            \n",
    "            faceImage = None\n",
    "            First = True\n",
    "            for i in range(batchSize):\n",
    "                if First is True:\n",
    "                    #print(miniDataset.iloc[i]['frameName'])\n",
    "                    img = cv2.imread('./Dataset/' + miniDataset.iloc[i]['frameName'])\n",
    "                    faceGrid = np.array([np.zeros((25,25))])\n",
    "                    faceGrid[0][miniDataset.iloc[i]['faceGridYmin']:miniDataset.iloc[i]['faceGridYmax'], miniDataset.iloc[i]['faceGridXmin']:miniDataset.iloc[i]['faceGridXmax']] = 1\n",
    "                    \n",
    "                    Grids = faceGrid\n",
    "                    faceImage = np.array([cv2.resize(img[int(miniDataset.iloc[i]['faceYmin']):int(miniDataset.iloc[i]['faceYmax']), int(miniDataset.iloc[i]['faceXmin']):int(miniDataset.iloc[i]['faceXmax']), :], (64,64), interpolation=cv2.INTER_AREA)  ])\n",
    "                    leftEyeImage = np.array([cv2.resize(img[int(miniDataset.iloc[i]['leftEyeYmin']):int(miniDataset.iloc[i]['leftEyeYmax']), int(miniDataset.iloc[i]['leftEyeXmin']):int(miniDataset.iloc[i]['leftEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)])\n",
    "                    rightEyeImage = np.array([cv2.resize(img[int(miniDataset.iloc[i]['rightEyeYmin']):int(miniDataset.iloc[i]['rightEyeYmax']), int(miniDataset.iloc[i]['rightEyeXmin']):int(miniDataset.iloc[i]['rightEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)])\n",
    "                    First = False\n",
    "                else:\n",
    "                    img = cv2.imread('./Dataset/' + miniDataset.iloc[i]['frameName'])\n",
    "                    faceGrid = np.array([np.zeros((25,25))])\n",
    "                    faceGrid[0][miniDataset.iloc[i]['faceGridYmin']:miniDataset.iloc[i]['faceGridYmax'], miniDataset.iloc[i]['faceGridXmin']:miniDataset.iloc[i]['faceGridXmax']] = 1\n",
    "                    \n",
    "                    #print(leftEyeImage.shape, rightEyeImage.shape, faceImage.shape, Grids.shape)\n",
    "                    \n",
    "                    Grids = np.append(Grids, faceGrid, axis = 0)\n",
    "                    leftEyeImage = np.append(leftEyeImage, np.array([cv2.resize(img[int(miniDataset.iloc[i]['leftEyeYmin']):int(miniDataset.iloc[i]['leftEyeYmax']), int(miniDataset.iloc[i]['leftEyeXmin']):int(miniDataset.iloc[i]['leftEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)]), axis = 0)\n",
    "                    rightEyeImage = np.append(rightEyeImage, np.array([cv2.resize(img[int(miniDataset.iloc[i]['rightEyeYmin']):int(miniDataset.iloc[i]['rightEyeYmax']), int(miniDataset.iloc[i]['rightEyeXmin']):int(miniDataset.iloc[i]['rightEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)]), axis = 0)\n",
    "                    faceImage = np.append(faceImage, np.array([cv2.resize( img[int(miniDataset.iloc[i]['faceYmin']):int(miniDataset.iloc[i]['faceYmax']), int(miniDataset.iloc[i]['faceXmin']):int(miniDataset.iloc[i]['faceXmax']), :] , (64,64), interpolation=cv2.INTER_AREA)  ]), axis = 0)\n",
    "                    \n",
    "            #print(\"END : \" , leftEyeImage.shape, rightEyeImage.shape, faceImage.shape, Grids.shape)\n",
    "            yield [leftEyeImage, rightEyeImage, faceImage, Grids], trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MAINDATASET : ', (1335663, 30))\n"
     ]
    }
   ],
   "source": [
    "dl = dataloader()\n",
    "#dl.mainCSVcreator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class training:\n",
    "    def __init__(self):\n",
    "        self.activation = 'relu'\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        #multiworker_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "        #multiworker_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(tf.distribute.experimental.CollectiveCommunication.NCCL)\n",
    "        #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "        \n",
    "        self.preMadeModel = self.getModel()\n",
    "        self.preMadeModel.compile(self.optimizer, loss = 'mse', metrics = [self.myAccuracy])\n",
    "    \n",
    "    def myAccuracy(self, y_true, y_pred):\n",
    "        diff = K.abs(y_true-y_pred) #absolute difference between correct and predicted values\n",
    "        correct = K.less(diff,0.05) #tensor with 0 for false values and 1 for true values\n",
    "        return K.mean(correct) #sum all 1's and divide by the total.\n",
    "    \n",
    "    def getModel(self):\n",
    "        leftEyeInput = tf.keras.layers.Input(shape = (64,64,3))\n",
    "        a = tf.keras.layers.Conv2D(96, kernel_size = 11, strides = 4, activation = self.activation)(leftEyeInput)\n",
    "        a = tf.keras.layers.MaxPooling2D(pool_size = 3)(a)\n",
    "        a = tf.keras.layers.BatchNormalization()(a)\n",
    "        a = tf.keras.layers.Flatten()(a)\n",
    "        lModel = tf.keras.models.Model(inputs = leftEyeInput, outputs = a)\n",
    "\n",
    "        rightEyeInput = tf.keras.layers.Input(shape = (64,64,3))\n",
    "        b = tf.keras.layers.Conv2D(96, kernel_size = 11, strides = 4, activation = self.activation)(rightEyeInput)\n",
    "        b = tf.keras.layers.MaxPooling2D(pool_size = 3)(b)\n",
    "        b = tf.keras.layers.BatchNormalization()(b)\n",
    "        b = tf.keras.layers.Flatten()(b)\n",
    "        rModel = tf.keras.models.Model(inputs = rightEyeInput, outputs = b)\n",
    "\n",
    "\n",
    "        outEyes = tf.keras.layers.concatenate([rModel.output, lModel.output])\n",
    "        outEyes = tf.keras.layers.Dense(128, activation = self.activation)(outEyes)\n",
    "\n",
    "        #Face\n",
    "        faceInput = tf.keras.layers.Input(shape = (64,64,3))\n",
    "        c = tf.keras.layers.Conv2D(96, kernel_size = 11, strides = 4, activation = self.activation)(faceInput)\n",
    "        c = tf.keras.layers.MaxPooling2D(pool_size = 3)(c)\n",
    "        c = tf.keras.layers.BatchNormalization()(c)\n",
    "        c = tf.keras.layers.Flatten()(c)\n",
    "        fModel = tf.keras.models.Model(inputs = faceInput, outputs = c)\n",
    "\n",
    "        #Face Grid\n",
    "        faceGridInput = tf.keras.layers.Input(shape = (25,25))\n",
    "        d = tf.keras.layers.Flatten()(faceGridInput)\n",
    "        gModel = tf.keras.models.Model(inputs = faceGridInput, outputs = d)\n",
    "\n",
    "        outFace = tf.keras.layers.concatenate([fModel.output, gModel.output])\n",
    "        outFace = tf.keras.layers.Dense(128, activation = self.activation)(outFace)\n",
    "\n",
    "        finalModel = tf.keras.layers.concatenate([outFace, outEyes])\n",
    "        finalModel = tf.keras.layers.Dense(128, activation = self.activation)(finalModel)\n",
    "        finalModel = tf.keras.layers.Dropout(0.25)(finalModel)\n",
    "        finalModel = tf.keras.layers.Dense(2)(finalModel)\n",
    "\n",
    "\n",
    "        model = tf.keras.models.Model(inputs = [leftEyeInput, rightEyeInput, faceInput, faceGridInput], outputs = finalModel)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainGenSeq(Sequence):\n",
    "    def __init__(self, batchSize):\n",
    "        self.batchSize = batchSize\n",
    "        \n",
    "        self.masterDataset = pd.read_csv('dataSet.csv')\n",
    "        self.splitcolumn = int(self.masterDataset.shape[0] * 0.9)\n",
    "        self.trainCSV = self.masterDataset.head(self.splitcolumn)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(self.trainCSV.shape[0] // self.batchSize)\n",
    "    \n",
    "    def getLen(self):\n",
    "        return int(self.trainCSV.shape[0] // self.batchSize)\n",
    "    \n",
    "    def __getitem__(self, trash):\n",
    "        masterDataset = self.trainCSV\n",
    "        leftEyeImage, rightEyeImage, faceImage, Grids = None, None, None, None\n",
    "        rows = random.sample(range(0, masterDataset.shape[0]), batchSize)\n",
    "        miniDataset = masterDataset.iloc[rows]\n",
    "        \n",
    "        trainY = miniDataset[['Xcam', 'Ycam']].to_numpy()\n",
    "        \n",
    "        faceImage = None\n",
    "        First = True\n",
    "        for i in range(batchSize):\n",
    "            if First is True:\n",
    "                #print(miniDataset.iloc[i]['frameName'])\n",
    "                img = cv2.imread('./Dataset/' + miniDataset.iloc[i]['frameName'])\n",
    "                faceGrid = np.array([np.zeros((25,25))])\n",
    "                faceGrid[0][miniDataset.iloc[i]['faceGridYmin']:miniDataset.iloc[i]['faceGridYmax'], miniDataset.iloc[i]['faceGridXmin']:miniDataset.iloc[i]['faceGridXmax']] = 1\n",
    "                \n",
    "                Grids = faceGrid\n",
    "                faceImage = np.array([cv2.resize(img[int(miniDataset.iloc[i]['faceYmin']):int(miniDataset.iloc[i]['faceYmax']), int(miniDataset.iloc[i]['faceXmin']):int(miniDataset.iloc[i]['faceXmax']), :], (64,64), interpolation=cv2.INTER_AREA)  ])\n",
    "                leftEyeImage = np.array([cv2.resize(img[int(miniDataset.iloc[i]['leftEyeYmin']):int(miniDataset.iloc[i]['leftEyeYmax']), int(miniDataset.iloc[i]['leftEyeXmin']):int(miniDataset.iloc[i]['leftEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)])\n",
    "                rightEyeImage = np.array([cv2.resize(img[int(miniDataset.iloc[i]['rightEyeYmin']):int(miniDataset.iloc[i]['rightEyeYmax']), int(miniDataset.iloc[i]['rightEyeXmin']):int(miniDataset.iloc[i]['rightEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)])\n",
    "                First = False   \n",
    "            else:\n",
    "                img = cv2.imread('./Dataset/' + miniDataset.iloc[i]['frameName'])\n",
    "                faceGrid = np.array([np.zeros((25,25))])\n",
    "                faceGrid[0][miniDataset.iloc[i]['faceGridYmin']:miniDataset.iloc[i]['faceGridYmax'], miniDataset.iloc[i]['faceGridXmin']:miniDataset.iloc[i]['faceGridXmax']] = 1\n",
    "                \n",
    "                #print(leftEyeImage.shape, rightEyeImage.shape, faceImage.shape, Grids.shape)\n",
    "                \n",
    "                Grids = np.append(Grids, faceGrid, axis = 0)\n",
    "                leftEyeImage = np.append(leftEyeImage, np.array([cv2.resize(img[int(miniDataset.iloc[i]['leftEyeYmin']):int(miniDataset.iloc[i]['leftEyeYmax']), int(miniDataset.iloc[i]['leftEyeXmin']):int(miniDataset.iloc[i]['leftEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)]), axis = 0)\n",
    "                rightEyeImage = np.append(rightEyeImage, np.array([cv2.resize(img[int(miniDataset.iloc[i]['rightEyeYmin']):int(miniDataset.iloc[i]['rightEyeYmax']), int(miniDataset.iloc[i]['rightEyeXmin']):int(miniDataset.iloc[i]['rightEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)]), axis = 0)\n",
    "                faceImage = np.append(faceImage, np.array([cv2.resize( img[int(miniDataset.iloc[i]['faceYmin']):int(miniDataset.iloc[i]['faceYmax']), int(miniDataset.iloc[i]['faceXmin']):int(miniDataset.iloc[i]['faceXmax']), :] , (64,64), interpolation=cv2.INTER_AREA)  ]), axis = 0)\n",
    "                \n",
    "        return [leftEyeImage, rightEyeImage, faceImage, Grids], trainY\n",
    "    \n",
    "class testGenSeq(Sequence):\n",
    "    def __init__(self, batchSize):\n",
    "        self.batchSize = batchSize\n",
    "        \n",
    "        self.masterDataset = pd.read_csv('dataSet.csv')\n",
    "        self.splitcolumn = int(self.masterDataset.shape[0] * 0.9)\n",
    "        self.testCSV = self.masterDataset.tail(self.masterDataset.shape[0] - self.splitcolumn)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(self.testCSV.shape[0] // self.batchSize)\n",
    "    \n",
    "    def getLen(self):\n",
    "        return int(self.testCSV.shape[0] // self.batchSize)\n",
    "    \n",
    "    def __getitem__(self, trash):\n",
    "        masterDataset = self.testCSV\n",
    "        leftEyeImage, rightEyeImage, faceImage, Grids = None, None, None, None\n",
    "        rows = random.sample(range(0, masterDataset.shape[0]), batchSize)\n",
    "        miniDataset = masterDataset.iloc[rows]\n",
    "        \n",
    "        trainY = miniDataset[['Xcam', 'Ycam']].to_numpy()\n",
    "        \n",
    "        faceImage = None\n",
    "        First = True\n",
    "        for i in range(batchSize):\n",
    "            if First is True:\n",
    "                #print(miniDataset.iloc[i]['frameName'])\n",
    "                img = cv2.imread('./Dataset/' + miniDataset.iloc[i]['frameName'])\n",
    "                faceGrid = np.array([np.zeros((25,25))])\n",
    "                faceGrid[0][miniDataset.iloc[i]['faceGridYmin']:miniDataset.iloc[i]['faceGridYmax'], miniDataset.iloc[i]['faceGridXmin']:miniDataset.iloc[i]['faceGridXmax']] = 1\n",
    "                \n",
    "                Grids = faceGrid\n",
    "                faceImage = np.array([cv2.resize(img[int(miniDataset.iloc[i]['faceYmin']):int(miniDataset.iloc[i]['faceYmax']), int(miniDataset.iloc[i]['faceXmin']):int(miniDataset.iloc[i]['faceXmax']), :], (64,64), interpolation=cv2.INTER_AREA)  ])\n",
    "                leftEyeImage = np.array([cv2.resize(img[int(miniDataset.iloc[i]['leftEyeYmin']):int(miniDataset.iloc[i]['leftEyeYmax']), int(miniDataset.iloc[i]['leftEyeXmin']):int(miniDataset.iloc[i]['leftEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)])\n",
    "                rightEyeImage = np.array([cv2.resize(img[int(miniDataset.iloc[i]['rightEyeYmin']):int(miniDataset.iloc[i]['rightEyeYmax']), int(miniDataset.iloc[i]['rightEyeXmin']):int(miniDataset.iloc[i]['rightEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)])\n",
    "                First = False   \n",
    "            else:\n",
    "                img = cv2.imread('./Dataset/' + miniDataset.iloc[i]['frameName'])\n",
    "                faceGrid = np.array([np.zeros((25,25))])\n",
    "                faceGrid[0][miniDataset.iloc[i]['faceGridYmin']:miniDataset.iloc[i]['faceGridYmax'], miniDataset.iloc[i]['faceGridXmin']:miniDataset.iloc[i]['faceGridXmax']] = 1\n",
    "                \n",
    "                #print(leftEyeImage.shape, rightEyeImage.shape, faceImage.shape, Grids.shape)\n",
    "                \n",
    "                Grids = np.append(Grids, faceGrid, axis = 0)\n",
    "                leftEyeImage = np.append(leftEyeImage, np.array([cv2.resize(img[int(miniDataset.iloc[i]['leftEyeYmin']):int(miniDataset.iloc[i]['leftEyeYmax']), int(miniDataset.iloc[i]['leftEyeXmin']):int(miniDataset.iloc[i]['leftEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)]), axis = 0)\n",
    "                rightEyeImage = np.append(rightEyeImage, np.array([cv2.resize(img[int(miniDataset.iloc[i]['rightEyeYmin']):int(miniDataset.iloc[i]['rightEyeYmax']), int(miniDataset.iloc[i]['rightEyeXmin']):int(miniDataset.iloc[i]['rightEyeXmax']), :], (64,64), interpolation=cv2.INTER_AREA)]), axis = 0)\n",
    "                faceImage = np.append(faceImage, np.array([cv2.resize( img[int(miniDataset.iloc[i]['faceYmin']):int(miniDataset.iloc[i]['faceYmax']), int(miniDataset.iloc[i]['faceXmin']):int(miniDataset.iloc[i]['faceXmax']), :] , (64,64), interpolation=cv2.INTER_AREA)  ]), axis = 0)\n",
    "                \n",
    "        return [leftEyeImage, rightEyeImage, faceImage, Grids], trainY\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "train = training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = train.preMadeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3827/9391 [===========>..................] - ETA: 25:39 - loss: 10.8464 - myAccuracy: 0.0144"
     ]
    }
   ],
   "source": [
    "batchSize = 128\n",
    "\n",
    "checkpoint_path = \"training_64_Large/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "trainSeq = trainGenSeq(batchSize)\n",
    "testSeq = testGenSeq(batchSize)\n",
    "\n",
    "history = model.fit(           trainSeq,\n",
    "                               #dl.load_data_train(batchSize),\n",
    "                               epochs = 5,\n",
    "                               steps_per_epoch = trainSeq.getLen(),\n",
    "                               #steps_per_epoch = dl.getEpochs_train(batchSize),\n",
    "                               verbose = 1,\n",
    "                               #validation_data = dl.load_data_test(batchSize),\n",
    "                               #validation_steps = dl.getEpochs_test(batchSize),\n",
    "                               validation_data = testSeq,\n",
    "                               validation_steps = testSeq.getLen(),\n",
    "                               use_multiprocessing = True,\n",
    "                               workers = 32\n",
    ")\n",
    "\n",
    "print(\"FINISED TRAINING\")\n",
    "\n",
    "model.save('largeModel_64.h5')\n",
    "model.save_weights('largeWeights_64.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, color='red', label='Training loss')\n",
    "plt.plot(epochs, val_loss, color='green', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Tensorflow2] *",
   "language": "python",
   "name": "conda-env-Tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
